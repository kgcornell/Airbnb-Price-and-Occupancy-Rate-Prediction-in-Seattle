{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import math\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3818, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = pd.read_csv('listings.csv')\n",
    "list2 = pd.read_csv('listings2.csv')\n",
    "nbhd = pd.read_csv('neighbourhoods.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "review1 = pd.read_csv('reviews.csv')\n",
    "review2 = pd.read_csv('reviews2.csv')\n",
    "amenities = pd.read_csv('Cata Feature CSV/amenities.csv')\n",
    "Integrate = pd.read_csv('Cata Feature CSV/IntegrateCata.csv')\n",
    "amenities.shape\n",
    "property_type = pd.read_csv('property_type.csv')\n",
    "property_type.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Data Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(list1.columns.values)\n",
    "# print(list1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(list2.columns.values)\n",
    "# print(list2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join list1 and list2 to create the x vector\n",
    "X = pd.concat([list1, list2], axis=1)\n",
    "# print(X.shape)\n",
    "# X.info(verbose = True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X=X[X['property_type'].notnull()]\n",
    "# X['property_type'].unique()\n",
    "# # Increasing the feature space\n",
    "# i=0\n",
    "# for item in X['property_type'].unique():\n",
    "#     a=X['property_type'] == X['property_type'].unique()[i]\n",
    "#     X[item] = a.map(lambda x: 1 if x == True else 0)\n",
    "#     i=i+1\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3818, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1=X.loc[:, X.dtypes == np.float64] #Extracting columns with values of type float \n",
    "Z2=X.loc[:, X.dtypes == np.int64]   #Extracting columns with values of type int\n",
    "Z3=X.loc[:, X.dtypes == np.object]   #Extracting columns with values of type categorical\n",
    "X_numeric=pd.concat([Z1,Z2], axis=1)\n",
    "X_cat = Z3\n",
    "X_numeric.shape\n",
    "# X_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"X_numeric has duplicate columns. The code below removes the duplicate columns\"\"\"\n",
    "_, i = np.unique(X_numeric.columns, return_index=True)\n",
    "X_Num_Cov=X_numeric.iloc[:, i]\n",
    "X_Num_Cov.to_csv('Numerical_FS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, i = np.unique(X_cat.columns, return_index=True)\n",
    "X_cat=X_cat.iloc[:, i]\n",
    "# print(X_cat.describe())\n",
    "# print(X_cat.info())\n",
    "X_cat.to_csv('Catgorical_FS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X and Y for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_select = X_Num_Cov[['reviews_per_month','accommodates','bathrooms','bedrooms','beds','guests_included','latitude','longitude','price']]\n",
    "X_select['avail'] = list2[['availability_365']]\n",
    "X_select = pd.concat([X_select, amenities, Integrate, property_type], axis=1)\n",
    "X_select = X_select.dropna()\n",
    "Y = X_select['reviews_per_month']\n",
    "X_select = X_select.drop(['reviews_per_month','Unnamed: 0'], axis = 1)\n",
    "# print(X_select.info())\n",
    "# X_select.columns\n",
    "# X_select.info(verbose = True, null_counts = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price\n",
      "1274    165\n",
      "765     120\n",
      "625      45\n",
      "1828     28\n",
      "448      95\n",
      "85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0700000000000003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_select, Y, test_size=num_test, random_state=23)\n",
    "X_train.shape\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "print(X_train[['price']].head())\n",
    "print(X_train.price[0])\n",
    "y_train.reviews_per_month[0]\n",
    "\n",
    "# X_test.shape\n",
    "# property_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression with Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEaCAYAAAAVJPDdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1149a0650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clf = Ridge(alpha=1.0)\n",
    "# clf.fit(X_train, y_train) \n",
    "# Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "#       normalize=True, random_state=None, solver='auto', tol=0.001)\n",
    "# ridgeTrain = clf.predict(X_train)\n",
    "# ridgeTest = clf.predict(X_test)\n",
    "# print(clf.score(X_test, y_test))\n",
    "# r2_score( y_test,ridgeTest)\n",
    "\n",
    "\n",
    "\n",
    "param_range = np.logspace(-7, 3, 3)\n",
    "# train_scores, test_scores = validation_curve(\n",
    "#     Ridge(), X_select, Y, param_name=\"alpha\", param_range=param_range,\n",
    "#     cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores, test_scores = validation_curve(Ridge(), X_select, Y, \"alpha\",param_range,cv=10, scoring=\"neg_mean_squared_error\",n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with Ridge Regression\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Score\")\n",
    "# plt.ylim(0.0, 5)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(X_train, y_train) \n",
    "# print(regr.score(X_test, y_test))\n",
    "# regr.get_params()\n",
    "# regr.coef_\n",
    "\n",
    "# title = \"Learning Curves (Linear Regression)\"\n",
    "# # SVC is more expensive so we do a lower number of CV iterations:\n",
    "# cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "# estimator = regr\n",
    "# plot_learning_curve(estimator, title, X_select, Y, (0, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = linear_model.Lasso(alpha=0.0, fit_intercept=True, \n",
    "#                          normalize=True, precompute=False, copy_X=True, \n",
    "#                          positive=False, random_state=None,tol=0.001)\n",
    "# clf.fit(X_train, y_train) \n",
    "# print(clf.score(X_test, y_test))\n",
    "\n",
    "# param_range = np.logspace(-7, 3, 3)\n",
    "# # train_scores, test_scores = validation_curve(\n",
    "# #     Ridge(), X_select, Y, param_name=\"alpha\", param_range=param_range,\n",
    "# #     cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "# train_scores, test_scores = validation_curve(Lasso(), X_select, Y, \"alpha\",param_range,cv=10, n_jobs=1)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# train_scores_std = np.std(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# plt.title(\"Validation Curve with Lasso Regression\")\n",
    "# plt.xlabel(\"alpha\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.ylim(0.0, 0.5)\n",
    "# lw = 2\n",
    "# plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "#              color=\"darkorange\", lw=lw)\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"darkorange\", lw=lw)\n",
    "# plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "#              color=\"navy\", lw=lw)\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"navy\", lw=lw)\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.31818768454812529"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "# RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "#            max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "clf = RandomForestRegressor(max_depth=20, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# print(clf.feature_importances_)\n",
    "RFTrain = clf.predict(X_train)\n",
    "RFTest = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14028045358039121"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(solver='adam', alpha=1e-4,hidden_layer_sizes=(1000, 6), random_state=1)\n",
    "clf.fit(X_train, y_train)                         \n",
    "# MLPRegressor(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "ANNTrain = clf.predict(X_train)\n",
    "ANNTest = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31704104434860447"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "# You can experiment with many other options here, using the same .fit() and .predict()\n",
    "# methods; see http://scikit-learn.org\n",
    "# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n",
    "gbm = xgb.XGBRegressor(max_depth=3, n_estimators=400, learning_rate=0.05).fit(X_train, y_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "predictions = gbm.predict(X_test)\n",
    "XGTrain = gbm.predict(X_train)\n",
    "XGTest = gbm.predict(X_test)\n",
    "gbm.score(X_test, y_test)\n",
    "r2_score(XGTest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "# create model\n",
    "tmodel = Sequential()\n",
    "tmodel.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                 kernel_initializer='normal', bias_initializer='zeros'))\n",
    "tmodel.add(Activation('relu'))\n",
    "\n",
    "for i in range(0, 8):\n",
    "    tmodel.add(Dense(units=100, kernel_initializer='normal',\n",
    "                     bias_initializer='zeros'))\n",
    "    tmodel.add(Activation('relu'))\n",
    "    tmodel.add(Dropout(.25))\n",
    "\n",
    "tmodel.add(Dense(units=1))\n",
    "tmodel.add(Activation('linear'))\n",
    "\n",
    "tmodel.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "tmodel.fit(X_train.values, y_train.values, epochs=100, verbose=0)\n",
    "\n",
    "DNTrain = tmodel.predict(X_train.values)\n",
    "DNTest = tmodel.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = tmodel.predict(X_test.values)\n",
    "loss_and_metrics = tmodel.evaluate(X_test.values, y_test.values, batch_size=128)\n",
    "print(loss_and_metrics)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test.values, classes))\n",
    "r2_score(y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42494698255111463"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rng = np.random.RandomState(1)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8),\n",
    "                          n_estimators=100, random_state=rng)\n",
    "\n",
    "regr_2.fit(X_train, y_train)\n",
    "regr_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': 'raise',\n",
       " 'estimator': AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, loss='linear', n_estimators=50,\n",
       "          random_state=None),\n",
       " 'fit_params': {},\n",
       " 'iid': True,\n",
       " 'n_jobs': 1,\n",
       " 'param_grid': {'base_estimator__max_depth': [4, 8, 12],\n",
       "  'learning_rate': [0.5, 0.7, 0.9, 1.1],\n",
       "  'n_estimators': [125, 150]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'n_estimators':[50,100,200,400]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters)\n",
    "# clf.fit(iris.data, iris.target)\n",
    "# sorted(clf.cv_results_.keys())\n",
    "# clf.get_params(deep=False)\n",
    "\n",
    "# base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None)\n",
    "\n",
    "params = {'base_estimator__max_depth': [4,8,12],\n",
    "          'learning_rate': [0.5, 0.7, 0.9, 1.1],\n",
    "          'n_estimators': [125, 150]}\n",
    "gs = GridSearchCV(AdaBoostRegressor(base_estimator=DecisionTreeRegressor()), params)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)\n",
    "gs.get_params(deep=False)\n",
    "# params = {'base_estimator__max_depth':[1,50],\n",
    "#           'base_estimator':[DecisionTreeClassifier(max_features=2), \n",
    "#                             DecisionTreeClassifier(max_features=10)]}\n",
    "# gs = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), params)\n",
    "\n",
    "# base_estimators = [DecisionTreeClassifier(max_depth=d) for d in range(1, 11)]\n",
    "# grid = GridSearchCV(AdaBoostClassifier(), dict(base_estimator=base_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__max_depth': 12, 'learning_rate': 0.9, 'n_estimators': 150}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensambling／Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold;\n",
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "# X_train.reset_index(inplace=True)\n",
    "# y_train.reset_index(inplace=True)\n",
    "# X_test.reset_index(inplace=True)\n",
    "# y_test.reset_index(inplace=True)\n",
    "X_train =X_train.as_matrix()\n",
    "y_train =y_train.as_matrix()\n",
    "X_test =X_test.as_matrix()\n",
    "y_test =y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te).flatten()\n",
    "        oof_test_skf[i, :] = clf.predict(x_test).flatten()\n",
    "    xx = oof_test_skf.mean(axis=0)\n",
    "    oof_test[:] = xx.flatten()\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=True, random_state=None, solver='auto', tol=0.001)\n",
    "rr_oof_train, rr_oof_test = get_oof(rr, X_train, y_train, X_test) # Ridge Regression\n",
    "ann = MLPRegressor(solver='adam', alpha=1e-4,hidden_layer_sizes=(1000, 6), random_state=1)\n",
    "rf_oof_train, rf_oof_test = get_oof(ann,X_train, y_train, X_test) # ANN\n",
    "ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8),\n",
    "                          n_estimators=100, random_state=rng)\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X_train, y_train, X_test) # AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( rr_oof_train, rf_oof_train, ada_oof_train), axis=1)\n",
    "x_test = np.concatenate(( rr_oof_test, rf_oof_test, ada_oof_test), axis=1)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "# x_train = preprocessing.scale(x_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "# You can experiment with many other options here, using the same .fit() and .predict()\n",
    "# methods; see http://scikit-learn.org\n",
    "# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n",
    "gbm = xgb.XGBRegressor(max_depth=3, n_estimators=400, learning_rate=0.05).fit(x_train, y_train)\n",
    "# X_test = preprocessing.scale(X_test)\n",
    "# X_test = pd.DataFrame(X_test)\n",
    "\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFTrain = pd.DataFrame(RFTrain)\n",
    "RFTest = pd.DataFrame(RFTest)\n",
    "XGTrain = pd.DataFrame(XGTrain)\n",
    "XGTest = pd.DataFrame(XGTest)\n",
    "ANNTrain = pd.DataFrame(ridgeTrain)\n",
    "ANNTest = pd.DataFrame(ridgeTest)\n",
    "x_train = np.concatenate(( ridgeTrain, ANNTrain, RFTrain ,XGTrain), axis=1)\n",
    "x_test = np.concatenate(( ridgeTest, ANNTest, RFTest, XGTest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30312291492016064"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rng = np.random.RandomState(1)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8),\n",
    "                          n_estimators=100, random_state=rng)\n",
    "\n",
    "regr_2.fit(x_train, y_train)\n",
    "pred = regr_2.predict(x_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "regr_2.score(x_test, y_test)\n",
    "r2_score( y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
